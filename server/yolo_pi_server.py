from flask import Flask, Response, jsonify, send_file, request
from flask_cors import CORS
import cv2
from picamera2 import Picamera2
from ultralytics import YOLO
import threading
import os
import time
from collections import deque
from threading import Thread
import sqlite3
import numpy as np

#Flask initialization
app = Flask(__name__)
CORS(app)  #Cross origin requests enabled

#Load the trained model for hand gestures
model = YOLO("yolo11n.pt")

#PiCamera initialization and settings
picam2 = Picamera2()
picam2.preview_configuration.main.size = (640, 480)
picam2.preview_configuration.main.format = "RGB888"
picam2.configure("preview")
picam2.start()

#User feedback SQLite database
DB_PATH = "feedback.db"
conn = sqlite3.connect(DB_PATH, check_same_thread=False)
c = conn.cursor()
c.execute("""
CREATE TABLE IF NOT EXISTS feedback (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    timestamp INTEGER,
    image_filename TEXT,
    detected_gesture TEXT,
    is_correct INTEGER,
    user_label TEXT
)
""")
conn.commit()

#Store the 10 most recently captured & processed images for review
IMG_FOLDER = "recently_processed"
os.makedirs(IMG_FOLDER, exist_ok=True) #Check that the dir exists
recent = deque(maxlen=10)

current_gesture = "None"  #Temporarily stores the gesture recognized by the yolo model
last_inf = 0
INF_INT = 0.5 #Image inference every 0.5s 

#Toggle to enable/disable image capture for privacy
#Enabled by default
capture_enabled = True

#Store recent inference metrics
metrics = deque(maxlen=20)  #Last 20 inferences

MODEL_SAVE_PATH = "custom_model.pt"
DEFAULT_MODEL_PATH = "yolo11n.pt"

def generate_frames():
    global current_gesture, last_inf
    while True:
        try:
            #Check if image capture is enabled
            if capture_enabled:
                frame = picam2.capture_array()
            else:
                #When capture is disabled, inform the user that privacy mode is enabled
                frame = np.zeros((480, 640, 3), dtype=np.uint8)
                cv2.putText(frame, "Camera Privacy Mode Enabled", (80, 240), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
                
                #Reset gesture when privacy mode is on
                current_gesture = "None"
                
                #Convert the frame to a jpeg image
                _, buffer = cv2.imencode('.jpg', frame)
                frame_bytes = buffer.tobytes()
                
                #Return/yield the frame 
                yield (b'--frame\r\n'
                    b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
                time.sleep(0.1)  #Short delay in privacy mode
                continue  #Skip the rest of the loop in privacy mode (no need for inference)

            curr_time = time.time()
            run_inf = curr_time - last_inf >= INF_INT

            #Run yolo model on the captured image
            if run_inf:
                inf_start = time.time()
                results = model(frame)
                inf_end = time.time()
                inf_time = inf_end - inf_start

                #Temporarily store detected gesture and confidence value during processing
                detected = "None" 
                confidence = 0.0

                for result in results:
                    for box in result.boxes:
                        class_id = int(box.cls[0])  #Id of the detected result
                        confidence = float(box.conf[0])

                        #Available gestures
                        gesture_names = ["thumbs_up", "open_palm", "fist", "thumbs_down", "point"] 
                        if class_id < len(gesture_names):
                            detected = gesture_names[class_id]

                #Update to the newly detected gesture if confident
                if detected != "None" and confidence > 0.4:
                    current_gesture = detected

                #Store metrics
                metrics.append({
                    "timestamp": int(time.time()),
                    "gesture": detected,
                    "confidence": confidence,
                    "inference_time": inf_time
                })

                #Attach the detected gesture to the frame
                annotated_frame = results[0].plot()

                #Save image and associated results generated by the yolo model
                capture_time = int(time.time())
                image_path = os.path.join(IMG_FOLDER, f"{capture_time}.jpg")
                cv2.imwrite(image_path, annotated_frame)

                #Add to the queue of most recent images
                recent.append({"image": image_path, "gesture": detected, "confidence": confidence})
            else:
                #Display the current gesture without image inference
                annotated_frame = frame.copy()
                cv2.putText(annotated_frame, f"Gesture: {current_gesture}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

            #Convert the frame to a jpeg image
            _, buffer = cv2.imencode('.jpg', annotated_frame)
            frame_bytes = buffer.tobytes()

            #Return/yield the frame 
            yield (b'--frame\r\n'
                b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
        
        except Exception as e: 
            print(f"Frame Generation Error: {e}")
            # Return an error frame
            error_frame = cv2.imread("error.jpg") if os.path.exists("error.jpg") else np.zeros((480, 640, 3), dtype=np.uint8)
            cv2.putText(error_frame, "Camera Error", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
            _, buffer = cv2.imencode('.jpg', error_frame)
            frame_bytes = buffer.tobytes()
            yield (b'--frame\r\n'
                   b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
            time.sleep(1)  # Wait before trying again

#API to view live video stream
@app.route('/video_feed')
def video_feed():
    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')

#API to get the latest gesture detected
@app.route('/gesture')
def get_gesture():
    return jsonify({"gesture": current_gesture})

#API to get the 10 most recent images and associated results
@app.route('/recent')
def get_recent():
    return jsonify(list(recent))

#API to view a specific image from the recently processed
@app.route('/image/<filename>')
def get_image(filename):
    image_path = os.path.join(IMG_FOLDER, filename)
    if(os.path.exists(image_path)):
        return send_file(image_path, mimetype='image/jpeg')
    else: 
        return jsonify({"error": "Image not found"}), 404
    
#API to send user feedback
@app.route('/feedback', methods=['POST'])
def post_feedback():
    """
    Expects JSON:
      {
        "image": "1609459200.jpg",
        "predicted": "thumbs_up",
        "is_correct": true,
        "user_label": "open_palm"  # optional if incorrect
      }
    """
    data = request.get_json()
    ts = int(time.time())
    c.execute(
      "INSERT INTO feedback (timestamp, image_filename, predicted_gesture, is_correct, user_label) VALUES (?,?,?,?,?)",
      (ts, data['image'], data['predicted'], int(data['is_correct']), data.get('user_label'))
    )
    conn.commit()
    return {"status": "ok"}

#Use human feedback to retrain the YOLO model periodically
def retrain():
    while True:
        #Retrain the model based on user feedback every hour
        time.sleep(3600)

        #Fetch gestures that were deemed incorrect by the user
        c.execute("SELECT image_filename, user_label FROM feedback WHERE is_correct=0 AND user_label IS NOT NULL")
        rows = c.fetchall()
        if not rows:
            continue

        #Prepare a dataset.yaml of the incorrectly identified images
        with open("feedback_dataset.yaml","w") as f:
            f.write("train: []\nval: []\nnames:\n  0: thumbs_up\n  1: open_palm\n  2: fist\n 3: thumbs_down\n 4: point\n") 

        #Fine tune YOLO model using these images
        model.train(data="feedback_dataset.yaml", epochs=2, imgsz=320, weights="yolo11n.pt")

        #Swap in the new weights 
        model = YOLO("runs/train/feedback_model/weights/best.pt")

#API to toggle privacy mode and image captures
@app.route('/toggle_capture', methods=['POST'])
def toggle_capture():
    global capture_enabled
    data = request.get_json()
    capture_enabled = data.get('enabled', True)
    return jsonify({"status": "ok", "capture_enabled": capture_enabled})

#API to get the active capture status
@app.route('/capture_status')
def get_capture_status():
    return jsonify({"capture_enabled": capture_enabled})

#API to get recent inference metrics
@app.route('/metrics')
def get_metrics():
    return jsonify(list(metrics))

#API endpoint to save current YOLO model weights
@app.route('/model/save', methods=['POST'])
def save_model():
    try:
        #Save current model weights
        model.save(MODEL_SAVE_PATH)
        return jsonify({"status": "ok", "message": "Model saved."})
    except Exception as e:
        return jsonify({"status": "error", "message": str(e)}), 500

#API endpoint to load a full set of saved YOLO model weights
@app.route('/model/load', methods=['POST'])
def load_model():
    global model
    try:
        if not os.path.exists(MODEL_SAVE_PATH):
            return jsonify({"status": "error", "message": "No saved model found."}), 404
        model = YOLO(MODEL_SAVE_PATH)
        return jsonify({"status": "ok", "message": "Model loaded."})
    except Exception as e:
        return jsonify({"status": "error", "message": str(e)}), 500

#API endpoint to reset weights to the default YOLO model
@app.route('/model/reset', methods=['POST'])
def reset_model():
    global model
    try:
        model = YOLO(DEFAULT_MODEL_PATH)
        return jsonify({"status": "ok", "message": "Model reset to default."})
    except Exception as e:
        return jsonify({"status": "error", "message": str(e)}), 500

#Run the retraining on a separate thread
threading.Thread(target=retrain, daemon=True).start()

if __name__ == "__main__":
    #Ensure dir exists
    os.makedirs(IMG_FOLDER, exist_ok=True)

    #Run the server
    app.run(host="0.0.0.0", port=5000, debug=True, threaded=True)