from flask import Flask, Response, jsonify, send_file
from flask_cors import CORS
import cv2
from picamera2 import Picamera2
from ultralytics import YOLO
import threading
import os
import time
from collections import deque

import sqlite3

#User feedback SQLite database
DB_PATH = "feedback.db"
conn = sqlite3.connect(DB_PATH, check_same_thread=False)
c = conn.cursor()
c.execute("""
CREATE TABLE IF NOT EXISTS feedback (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    timestamp INTEGER,
    image_filename TEXT,
    detected_gesture TEXT,
    is_correct INTEGER,
    user_label TEXT
)
""")
conn.commit()

#Flask initialization
app = Flask(__name__)
CORS(app)  #Cross origin requests enabled

#Load the trained model for hand gestures
model = YOLO("yolo11n.pt")

#PiCamera initialization and settings
picam2 = Picamera2()
picam2.preview_configuration.main.size = (640, 480)
picam2.preview_configuration.main.format = "RGB888"
picam2.configure("preview")
picam2.start()

#Store the 10 most recently captured & processed images for review
IMG_FOLDER = "recently_processed"
recent = deque(maxlen=10)

current_gesture = "None"  #Temporarily stores the gesture recognized by the yolo model

def generate_frames():
    global current_gesture
    while True:
        frame = picam2.capture_array()

        #Run yolo model on the captured image
        results = model(frame)

        #Temporarily store detected gesture and confidence value during processing
        detected = "None" 
        confidence = 0.0

        for result in results:
            for box in result.boxes:
                class_id = int(box.cls[0])  #Id of the detected result
                confidence = float(box.conf[0])

                #Available gestures
                gesture_names = ["thumbs_up", "open_palm", "fist", "thumbs_down", "point"] 
                if class_id < len(gesture_names):
                    current_gesture = gesture_names[class_id]

        #Update to the newly processed gesture
        current_gesture = detected

        #Attach the detected gesture to the frame
        annotated_frame = results[0].plot()

        #Save image and associated results generated by the yolo model
        capture_time = int(time.time())
        image_path = os.path.join(IMG_FOLDER, f"{capture_time}.jpg")
        cv2.imwrite(image_path, annotated_frame)

        #Add to the queue of most recent images
        recent.append({"image": image_path, "gesture": detected, "confidence": confidence})

        #Convert the frame to a jpeg image
        _, buffer = cv2.imencode('.jpg', annotated_frame)
        frame_bytes = buffer.tobytes()

        #Return/yield the frame 
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
        
#API to view live video stream
@app.route('/video_feed')
def video_feed():
    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')

#API to get the latest gesture detected
@app.route('/gesture')
def get_gesture():
    return jsonify({"gesture": current_gesture})

#API to get the 10 most recent images and associated results
@app.route('/recent')
def get_recent():
    return jsonify(list(recent))

#API to view a specific image from the recently processed
@app.route('/image/<filename>')
def get_image(filename):
    image_path = os.path.join(IMG_FOLDER, filename)
    if(os.path.exists(image_path)):
        return send_file(image_path, mimetype='image/jpeg')
    else: 
        return jsonify({"error": "Image not found"}), 404

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000, debug=True, threaded=True)